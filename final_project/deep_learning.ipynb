{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# Build Example Data is CSV format, but use Iris data\n",
    "from sklearn import datasets\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertOneHot(y):\n",
    "    \n",
    "    y_onehot=[0]*len(y)\n",
    "    for i,j in enumerate(y):\n",
    "        y_onehot[i]=[0]*(y.max() + 1)\n",
    "        y_onehot[i][j]=1\n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./X_train.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"./y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = train_y[\"5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_one = convertOneHot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15119,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  A number of features, 4 in this example\n",
    "#  B = 3 species of Iris (setosa, virginica and versicolor)\n",
    "A=X_train.shape[1] # Number of features, Note first is y\n",
    "B=len(y_one[0])\n",
    "tf_in = tf.placeholder(\"float\", [None, A]) # Features\n",
    "tf_weight = tf.Variable(tf.zeros([A,B]))\n",
    "tf_bias = tf.Variable(tf.zeros([B]))\n",
    "tf_softmax = tf.nn.softmax(tf.matmul(tf_in,tf_weight) + tf_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training via backpropagation\n",
    "tf_softmax_correct = tf.placeholder(\"float\", [None,B])\n",
    "tf_cross_entropy = -tf.reduce_sum(tf_softmax_correct*tf.log(tf_softmax))\n",
    "\n",
    "# Train using tf.train.GradientDescentOptimizer\n",
    "tf_train_step = tf.train.GradientDescentOptimizer(0.01).minimize(tf_cross_entropy)\n",
    "\n",
    "# Add accuracy checking nodes\n",
    "tf_correct_prediction = tf.equal(tf.argmax(tf_softmax,1), tf.argmax(tf_softmax_correct,1))\n",
    "tf_accuracy = tf.reduce_mean(tf.cast(tf_correct_prediction, \"float\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'HistogramSummary_3:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and run\n",
    "sess = tf.Session()\n",
    "#sess = tf.InteractiveSession()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "# Build the summary operation based on the TF collection of Summaries.\n",
    "#tf.train.write_graph(sess.graph_def, TMPDir + '/logsd','graph.pbtxt')\n",
    "\n",
    "#acc = tf.scalar_summary(\"Accuracy:\", tf_accuracy)\n",
    "tf.scalar_summary(\"Accuracy:\", tf_accuracy)\n",
    "tf.histogram_summary('weights', tf_weight)\n",
    "tf.histogram_summary('bias', tf_bias)\n",
    "tf.histogram_summary('softmax', tf_softmax)\n",
    "tf.histogram_summary('accuracy', tf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15120, 34)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 40\n",
    "display_step = 1\n",
    "total_train = X_train.shape[0]\n",
    "A = X_train.shape[1]\n",
    "B = len(y_one[0])\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, A]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, B]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([A, B]))\n",
    "b = tf.Variable(tf.zeros([B]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[i:i+batch_size].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= nan\n",
      "Epoch: 0002 cost= nan\n",
      "Epoch: 0003 cost= nan\n",
      "Epoch: 0004 cost= nan\n",
      "Epoch: 0005 cost= nan\n",
      "Epoch: 0006 cost= nan\n",
      "Epoch: 0007 cost= nan\n",
      "Epoch: 0008 cost= nan\n",
      "Epoch: 0009 cost= nan\n",
      "Epoch: 0010 cost= nan\n",
      "Epoch: 0011 cost= nan\n",
      "Epoch: 0012 cost= nan\n",
      "Epoch: 0013 cost= nan\n",
      "Epoch: 0014 cost= nan\n",
      "Epoch: 0015 cost= nan\n",
      "Epoch: 0016 cost= nan\n",
      "Epoch: 0017 cost= nan\n",
      "Epoch: 0018 cost= nan\n",
      "Epoch: 0019 cost= nan\n",
      "Epoch: 0020 cost= nan\n",
      "Epoch: 0021 cost= nan\n",
      "Epoch: 0022 cost= nan\n",
      "Epoch: 0023 cost= nan\n",
      "Epoch: 0024 cost= nan\n",
      "Epoch: 0025 cost= nan\n",
      "Optimization Finished!\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(total_train/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = X_train[i:i+batch_size], y_one[i:i+batch_size]\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: X_train[:3000], y: y_one[:3000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "B=len(y_one[0])\n",
    "tf_in = tf.placeholder(\"float\", [None, A]) # Features\n",
    "tf_weight = tf.Variable(tf.zeros([A,B]))\n",
    "tf_bias = tf.Variable(tf.zeros([B]))\n",
    "tf_softmax = tf.nn.softmax(tf.matmul(tf_in,tf_weight) + tf_bias)\n",
    "\n",
    "\n",
    "\n",
    "# Training via backpropagation\n",
    "tf_softmax_correct = tf.placeholder(\"float\", [None,B])\n",
    "tf_cross_entropy = -tf.reduce_sum(tf_softmax_correct*tf.log(tf_softmax))\n",
    "\n",
    "# Train using tf.train.GradientDescentOptimizer\n",
    "tf_train_step = tf.train.GradientDescentOptimizer(0.01).minimize(tf_cross_entropy)\n",
    "\n",
    "# Add accuracy checking nodes\n",
    "tf_correct_prediction = tf.equal(tf.argmax(tf_softmax,1), tf.argmax(tf_softmax_correct,1))\n",
    "tf_accuracy = tf.reduce_mean(tf.cast(tf_correct_prediction, \"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmp Dir did not exist\n"
     ]
    }
   ],
   "source": [
    "# Recreate logging dir\n",
    "import shutil, os, sys\n",
    "TMPDir='./tenIrisSave'\n",
    "try:\n",
    " shutil.rmtree(TMPDir)\n",
    "except:\n",
    " print \"Tmp Dir did not exist\"\n",
    "os.mkdir(TMPDir, 0755 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'HistogramSummary_7:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and run\n",
    "sess = tf.Session()\n",
    "#sess = tf.InteractiveSession()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "# Build the summary operation based on the TF collection of Summaries.\n",
    "tf.train.write_graph(sess.graph_def, TMPDir + '/logsd','graph.pbtxt')\n",
    "\n",
    "#acc = tf.scalar_summary(\"Accuracy:\", tf_accuracy)\n",
    "tf.scalar_summary(\"Accuracy:\", tf_accuracy)\n",
    "tf.histogram_summary('weights', tf_weight)\n",
    "tf.histogram_summary('bias', tf_bias)\n",
    "tf.histogram_summary('softmax', tf_softmax)\n",
    "tf.histogram_summary('accuracy', tf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "summary_op = tf.merge_all_summaries()\n",
    "#summary_writer = tf.train.SummaryWriter('./tenIrisSave/logs',graph_def=sess.graph_def)\n",
    "summary_writer = tf.train.SummaryWriter(TMPDir + '/logs',sess.graph_def)\n",
    "\n",
    "# This will not work. You need the full path.                                        \n",
    "# tensorboard --logdir=./tenIrisSave/   # BAD!\n",
    "# tensorboard --logdir=$(pwd)/tenIrisSave/  # Good!\n",
    "\n",
    "# This is for saving all our work\n",
    "saver = tf.train.Saver([tf_weight,tf_bias])\n",
    "\n",
    "print(\"...\")\n",
    "# Run the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [15119,8] vs. [15120,8]\n\t [[Node: gradients_3/mul_3_grad/BroadcastGradientArgs = BroadcastGradientArgs[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients_3/mul_3_grad/Shape, gradients_3/mul_3_grad/Shape_1)]]\nCaused by op u'gradients_3/mul_3_grad/BroadcastGradientArgs', defined at:\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-44552f370a76>\", line 15, in <module>\n    tf_train_step = tf.train.GradientDescentOptimizer(0.01).minimize(tf_cross_entropy)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 190, in minimize\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 241, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 399, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 140, in _broadcast_gradient_args\n    name=name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'mul_3', defined at:\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 17 identical lines from previous traceback]\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-44552f370a76>\", line 12, in <module>\n    tf_cross_entropy = -tf.reduce_sum(tf_softmax_correct*tf.log(tf_softmax))\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 518, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1039, in mul\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a4c4fa21f992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msaved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtf_in\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_softmax_correct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_one\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Print accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtf_in\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_softmax_correct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test_onehot\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m       raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[0;32m--> 659\u001b[0;31m                                             e.code)\n\u001b[0m\u001b[1;32m    660\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [15119,8] vs. [15120,8]\n\t [[Node: gradients_3/mul_3_grad/BroadcastGradientArgs = BroadcastGradientArgs[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients_3/mul_3_grad/Shape, gradients_3/mul_3_grad/Shape_1)]]\nCaused by op u'gradients_3/mul_3_grad/BroadcastGradientArgs', defined at:\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-44552f370a76>\", line 15, in <module>\n    tf_train_step = tf.train.GradientDescentOptimizer(0.01).minimize(tf_cross_entropy)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 190, in minimize\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 241, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 399, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 140, in _broadcast_gradient_args\n    name=name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'mul_3', defined at:\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 17 identical lines from previous traceback]\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-44552f370a76>\", line 12, in <module>\n    tf_cross_entropy = -tf.reduce_sum(tf_softmax_correct*tf.log(tf_softmax))\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 518, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1039, in mul\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/Sakamoto/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k=[]\n",
    "saved=0\n",
    "for i in range(100):\n",
    "    sess.run(tf_train_step, feed_dict={tf_in: X_train, tf_softmax_correct: y_one})\n",
    "# Print accuracy\n",
    "    result = sess.run(tf_accuracy, feed_dict={tf_in: x_test, tf_softmax_correct: y_test_onehot})\n",
    "    print \"Run {},{}\".format(i,result)\n",
    "    k.append(result)\n",
    "    summary_str = sess.run(summary_op,feed_dict={tf_in: x_test, tf_softmax_correct: y_test_onehot})\n",
    "    summary_writer.add_summary(summary_str, i)\n",
    "    if result == 1 and saved == 0:\n",
    "        saved=1\n",
    "        print \"saving\"\n",
    "        saver.save(sess,\"./tenIrisSave/saveOne\")\n",
    "\n",
    "\n",
    "k=np.array(k)\n",
    "print(np.where(k==k.max()))\n",
    "print \"Max: {}\".format(k.max())\n",
    "\n",
    "print \"\\nTo see the output, run the following:\"\n",
    "print \"tensorboard --logdir=$(pwd)/tenIrisSave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
